---
title: 科大讯飞语音合成的引入
date: 2016-08-16 22:29:07
categories: 总结
tags: 总结，科大讯飞，语音合成

---
关于第三方 SDK 的引入，很多情况下直接查看官方文档就够了，之前的我也一直这样认为，直到遇到了科大讯飞的语音合成。其实他和其他第三方 SDK 的引入没有太大的区别，唯一的一点不同或许就是需要引入 .so 文件，这个 .so 文件正是坑所在。既然都说了，那就顺便把语音合成这部分也说一下吧。
在语音合成这方面，据我所知科大讯飞算是做得很不错的了，要用到人家的 SDK 那注册个账号是少不了的了。这部分就省略了，直接注册登录，然后创建应用，这时会给你个 appID ，嗯，还要绑定手机号和微信号（这点略坑）。都弄好后就下载 SDK ,解压出来是这样的：<br/>
![](http://oaydqd1yy.bkt.clouddn.com/png/sdk.png)
<!-- more -->
### 1、包的导入(包括 .so 文件)
直接把 SDK 中 lib 文件夹下的 __所有文件__ 复制到 Android 工程下的 lib 目录下（如果 Android 工程下面没有 lib文件夹 ，就自己新建一个 lib 文件夹），为什么要复制所有呢？这里有个坑，一开始按照官方 SDK 只复制了 armeabi、armeabi-v7a、mips 这三个文件夹，但是在一切都弄好准备测试是一直报“引擎不支持（21002）”，我以为是 .so 文件引入失败，花了好一会功夫才搞清楚原来要导入所有文件，这是 lib 下的所有文件：<br/>
![](http://oaydqd1yy.bkt.clouddn.com/png/lib.png)
我的 Android 工程目录<br/>
![](http://oaydqd1yy.bkt.clouddn.com/png/copy.png)
这里有一点要注意，导入的 jar 包还需对它右键 －> Add As Library<br/>
![](http://oaydqd1yy.bkt.clouddn.com/png/aslibrary.png)
jar 包是引入了，那 .so 文件呢？接下来才是精华所在
### 2、.so 文件的引入
#### 2.1、添加引入语句
刚刚已经把 .so 文件都复制到 Android 工程的 lib 目录下了，但是还不够。打开 module 的 build.gradle 文件，在里面的 android 标签下添加一句 sourceSets.main.jniLibs.srcDirs = ['libs']<br/>
![](http://oaydqd1yy.bkt.clouddn.com/png/build.png)
我的整个 build.gradle 文件是这样的：<br/>
``` xml
apply plugin: 'com.android.application'

android {
    compileSdkVersion 23
    buildToolsVersion '22.0.0'

    defaultConfig {
        applicationId "com.catt.temp"
        minSdkVersion 19
        targetSdkVersion 23
        versionCode 1
        versionName "1.0"
    }
    buildTypes {
        release {
            minifyEnabled false
            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
        }
    }
    sourceSets.main.jniLibs.srcDirs = ['libs']
}

dependencies {
    compile fileTree(dir: 'libs', include: ['*.jar'])
    testCompile 'junit:junit:4.12'
    compile 'com.android.support:appcompat-v7:23.3.0'
    compile 'com.android.support:support-v4:23.3.0'
    compile 'com.android.support:design:23.3.0'
    compile 'com.github.liuguangqiang.swipeback:library:1.0.2@aar'
    compile files('libs/ksoap2-android-assembly-3.3.0-jar-with-dependencies.jar')
    compile files('libs/Msc.jar')
    compile files('libs/Sunflower.jar')
}
```
#### 2.2、Make Project
此时还差一步，就是 Build -> Make Project <br/>
![](http://oaydqd1yy.bkt.clouddn.com/png/make.png)
这样就会在工程生成一个 jniLibs 的东东，就像是这样的：<br/>
![](http://oaydqd1yy.bkt.clouddn.com/jnilibs.png)
### 3、代码实现
到这里所有的准备工作都做好了，接下来是代码实现，这部分在 SDK 上有，可以直接复制过来，贴上我的代码(AndroidMainfest.xml 中的权限看 SDK 就好了，这里就不贴出来了)：<br/>
``` Java
package com.catt.temp.util;
import android.content.Context;
import android.os.Bundle;
import com.iflytek.cloud.SpeechConstant;
import com.iflytek.cloud.SpeechError;
import com.iflytek.cloud.SpeechSynthesizer;
import com.iflytek.cloud.SpeechUtility;
import com.iflytek.cloud.SynthesizerListener;

/**
 * 语音合成
 */
public class MSCUtil {
    private Context mContext;
    private SpeechSynthesizer mSynthesizer;
    private static final String TEXT = "警告，当前机房温度已达到";

    public MSCUtil(Context context) {
        this.mContext = context;
        SpeechUtility.createUtility(mContext, SpeechConstant.APPID +"=57b27fce");
        mSynthesizer = SpeechSynthesizer.createSynthesizer(mContext, null);
    }

    /**
     * 开始
     */
    public void startSpeek() {
        // 设置发音人
        mSynthesizer.setParameter(SpeechConstant.VOICE_NAME, "xiaoyan");
        // 设置语速
        mSynthesizer.setParameter(SpeechConstant.SPEED, "50");
        // 设置音量，范围0～100
        mSynthesizer.setParameter(SpeechConstant.VOLUME, "80");
        // 设置云端
        mSynthesizer.setParameter(SpeechConstant.ENGINE_TYPE, SpeechConstant.TYPE_CLOUD);
        mSynthesizer.setParameter(SpeechConstant.TTS_AUDIO_PATH, "./sdcard/iflytek.pcm");
        mSynthesizer.startSpeaking(TEXT, synListener);
    }

    /**
     * 停止
     */
    public void stopSpeek() {
        mSynthesizer.stopSpeaking();
    }

    /**
     * 合成监听器
     */
    private SynthesizerListener synListener = new SynthesizerListener() {
        //会话结束回调接口,没有错误时,error为null
        public void onCompleted(SpeechError error) {
            // 循环
            mSynthesizer.startSpeaking(TEXT, synListener);
        }

        @Override
        public void onEvent(int i, int i1, int i2, Bundle bundle) {}
        //缓冲进度回调 //percent为缓冲进度0~100,beginPos为缓冲音频在文本中开始位置,endPos表示缓冲音频在文本中结束位置,info为附加信息。
        public void onBufferProgress(int percent, int beginPos, int endPos, String info) {}
        //开始播放
        public void onSpeakBegin() {}
        //暂停播放
        public void onSpeakPaused() {}
        //播放进度回调 //percent为播放进度0~100,beginPos为播放音频在文本中开始位置,endPos表示播放音频在文本中结束位置.
        public void onSpeakProgress(int percent, int beginPos, int endPos) {}
        //恢复播放回调接口
        public void onSpeakResumed() {}
    };
}
```
注释都很详细了，在 onCompleted() 方法中调用 mSynthesizer.startSpeaking(TEXT, synListener); 这一句是我自己的需求，因为我想要它循环播放语音，直到我手动的停止。TEXT 就是需要转换为语音的文字，自己定制。

很郁闷的事，今天我发现官方 SDK 改了，变成了这样：<br/>
![](http://oaydqd1yy.bkt.clouddn.com/alllib.png)
一开始不是这样的，不然我也不会浪费这么多时间在这，只能说很坑...
